# FLUENTAI.NET - Universal AI SDK for .NET

[![.NET](https://img.shields.io/badge/.NET-8.0-purple.svg)](https://dotnet.microsoft.com/)
[![NuGet](https://img.shields.io/nuget/v/FluentAI.NET.svg)](https://www.nuget.org/packages/FluentAI.NET/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen.svg)]()
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)]()
[![Coverage](https://img.shields.io/badge/coverage-87%25-yellow.svg)](docs/AUDIT-EXECUTIVE-SUMMARY.md)
[![Documentation](https://img.shields.io/badge/docs-comprehensive-brightgreen.svg)](docs/)
[![Audit](https://img.shields.io/badge/audit-completed-blue.svg)](docs/AUDIT-EXECUTIVE-SUMMARY.md)

FluentAI.NET is a comprehensive, production-ready SDK that unifies access to multiple AI chat models under a single, elegant API. Built for .NET developers who want enterprise-grade AI capabilities without vendor lock-in or complex configuration.

## ğŸ“‹ Table of Contents

- [âœ¨ Key Features](#-key-features)
- [ğŸš€ Supported Providers](#-supported-providers)
- [ğŸ“¦ Installation](#-installation)
- [ğŸ¯ Quick Start](#-quick-start)
- [ğŸ”§ Advanced Usage](#-advanced-usage)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ“– Documentation](#-documentation)
- [ğŸ§ª Examples & Demos](#-examples--demos)
- [ğŸ› ï¸ Integration Guides](#ï¸-integration-guides)
- [ğŸ” Security](#-security)
- [âš¡ Performance](#-performance)
- [ğŸ§ª Testing](#-testing)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)
- [ğŸ†˜ Support](#-support)

## âœ¨ Key Features

### ğŸŒŸ **Production-Ready Architecture**
âœ… **Multi-Provider Support** - OpenAI, Anthropic, Google AI with unified interface  
âœ… **Enterprise Security** - Input sanitization, content filtering, risk assessment  
âœ… **Advanced Resilience** - Rate limiting, automatic failover, circuit breakers  
âœ… **Performance Optimized** - Response caching, memory management, streaming support  
âœ… **Observability Built-in** - Comprehensive logging, metrics, health checks  
âœ… **Dependency Injection** - First-class support for modern .NET patterns  

### ğŸ”§ **Developer Experience**
âœ… **Simple Integration** - Single interface for all providers  
âœ… **Rich Configuration** - Environment variables, appsettings.json, Azure Key Vault  
âœ… **Comprehensive Examples** - Working demos for all project types  
âœ… **Extensive Documentation** - API reference, integration guides, troubleshooting  
âœ… **Strong Typing** - Full IntelliSense support and compile-time safety  
âœ… **Async/Await** - Native async support with cancellation tokens  

### ğŸ›¡ï¸ **Security & Compliance**
âœ… **Input Validation** - Prompt injection detection and prevention  
âœ… **Content Filtering** - Configurable safety filters and risk assessment  
âœ… **Secure Logging** - Automatic redaction of sensitive data  
âœ… **API Key Protection** - Secure storage and rotation support  
âœ… **GDPR Compliance** - Data protection and privacy controls

### ğŸš€ **Advanced Performance Features (New!)**
âœ… **Token Streaming with Backpressure** - Prevent overwhelming consumers with bounded buffers  
âœ… **Parallelized Batch Operations** - Process multiple requests 5-10x faster  
âœ… **Model Benchmarking Tools** - Compare performance, cost, and quality across providers  
âœ… **Automatic Token Counting** - Track usage and optimize context windows  
âœ… **Semantic Caching** - 15-30% better hit rates with similarity matching  
âœ… **Memory Abstractions** - Short-term, long-term, and semantic memory patterns  
âœ… **Middleware Pipeline** - Extensible plugin architecture for custom processing  
âœ… **Conversation State Management** - Persistent, scalable conversation tracking

**[ğŸ“– See Complete Roadmap Implementation](docs/ROADMAP-IMPLEMENTATION.md)**  

## ğŸš€ Supported Providers

| Provider    | Capability      |
| ----------- | --------------- |
| OpenAI      | Text generation |
| Anthropic   | Text generation |
| Google AI   | Text generation |


**Extensible Architecture** - Add custom providers with minimal code

## ğŸ“¦ Installation

```bash
# Single package includes all providers - no additional dependencies needed
dotnet add package FluentAI.NET
```

**Supported Platforms:**
- .NET 8.0+
- Windows, Linux, macOS
- Docker containers
- Azure Functions, AWS Lambda
- Blazor Server, Blazor WebAssembly

## ğŸ¯ Quick Start

### 1. Set Up API Keys

```bash
# Environment Variables (Recommended)
export OPENAI_API_KEY="your-openai-api-key"
export ANTHROPIC_API_KEY="your-anthropic-api-key"
export GOOGLE_API_KEY="your-google-api-key"
```

### 2. Configure Services

#### ASP.NET Core
```csharp
var builder = WebApplication.CreateBuilder(args);

// Add FluentAI with automatic provider detection
builder.Services.AddAiSdk(builder.Configuration)
    .AddOpenAiChatModel(builder.Configuration)
    .AddAnthropicChatModel(builder.Configuration)
    .AddGoogleGeminiChatModel(builder.Configuration);

var app = builder.Build();
```

#### Console Application
```csharp
var builder = Host.CreateDefaultBuilder(args)
    .ConfigureServices((context, services) =>
    {
        services.AddAiSdk(context.Configuration)
            .AddOpenAiChatModel(context.Configuration);
    });

using var host = builder.Build();
```

### 3. Configuration (appsettings.json)

```json
{
  "AiSdk": {
    "DefaultProvider": "OpenAI",
    "Failover": {
      "PrimaryProvider": "OpenAI",
      "FallbackProvider": "Anthropic"
    }
  },
  "OpenAI": {
    "Model": "gpt-4",
    "MaxTokens": 2000,
    "RequestTimeout": "00:02:00",
    "PermitLimit": 100,
    "WindowInSeconds": 60
  },
  "Anthropic": {
    "Model": "claude-3-sonnet-20240229",
    "MaxTokens": 2000,
    "RequestTimeout": "00:02:00",
    "PermitLimit": 50,
    "WindowInSeconds": 60
  }
}
```

### 4. Use in Your Code

```csharp
public class ChatController : ControllerBase
{
    private readonly IChatModel _chatModel;

    public ChatController(IChatModel chatModel)
    {
        _chatModel = chatModel;
    }

    [HttpPost("chat")]
    public async Task<IActionResult> Chat([FromBody] ChatRequest request)
    {
        var messages = new[]
        {
            new ChatMessage(ChatRole.System, "You are a helpful assistant."),
            new ChatMessage(ChatRole.User, request.Message)
        };

        try
        {
            var response = await _chatModel.GetResponseAsync(messages);
            return Ok(new { response = response.Content, model = response.ModelId });
        }
        catch (AiSdkRateLimitException)
        {
            return StatusCode(429, "Rate limit exceeded. Please try again later.");
        }
        catch (AiSdkException ex)
        {
            return BadRequest($"AI service error: {ex.Message}");
        }
    }

    [HttpPost("stream")]
    public async IAsyncEnumerable<string> StreamChat([FromBody] ChatRequest request)
    {
        var messages = new[] { new ChatMessage(ChatRole.User, request.Message) };
        
        await foreach (var token in _chatModel.StreamResponseAsync(messages))
        {
            yield return token;
        }
    }
}
```

## ğŸ”§ Advanced Usage

### Multi-Provider with Automatic Failover

```csharp
// Configuration enables automatic failover
{
  "AiSdk": {
    "Failover": {
      "PrimaryProvider": "OpenAI",
      "FallbackProvider": "Anthropic"
    }
  }
}

// Transparent failover - no code changes needed
var response = await _chatModel.GetResponseAsync(messages);
// Uses OpenAI first, automatically falls back to Anthropic on errors
```

### Provider-Specific Options

```csharp
// OpenAI with advanced options
var openAiOptions = new OpenAiRequestOptions
{
    Temperature = 0.8f,
    MaxTokens = 1500,
    TopP = 0.9f,
    FrequencyPenalty = 0.1f
};

var response = await _chatModel.GetResponseAsync(messages, openAiOptions);

// Anthropic with system prompt
var anthropicOptions = new AnthropicRequestOptions
{
    SystemPrompt = "You are an expert software architect.",
    Temperature = 0.7f,
    MaxTokens = 2000
};
```

### Security Features

```csharp
public class SecureChatService
{
    private readonly IChatModel _chatModel;
    private readonly IInputSanitizer _sanitizer;

    public async Task<string> ProcessSecurelyAsync(string userInput)
    {
        // Security validation
        if (!_sanitizer.IsContentSafe(userInput))
            throw new SecurityException("Unsafe content detected");

        // Risk assessment
        var risk = _sanitizer.AssessRisk(userInput);
        if (risk.RiskLevel >= SecurityRiskLevel.High)
            throw new SecurityException($"High risk content: {string.Join(", ", risk.DetectedConcerns)}");

        // Sanitize input
        var sanitizedInput = _sanitizer.SanitizeContent(userInput);
        
        var messages = new[] { new ChatMessage(ChatRole.User, sanitizedInput) };
        var response = await _chatModel.GetResponseAsync(messages);
        
        return response.Content;
    }
}
```

### Performance Optimization

```csharp
public class PerformantChatService
{
    private readonly IChatModel _chatModel;
    private readonly IResponseCache _cache;
    private readonly IPerformanceMonitor _monitor;

    public async Task<ChatResponse> GetCachedResponseAsync(IEnumerable<ChatMessage> messages)
    {
        // Check cache first
        var cachedResponse = await _cache.GetAsync(messages);
        if (cachedResponse != null)
            return cachedResponse;

        // Monitor performance
        using var operation = _monitor.StartOperation("ChatCompletion");
        
        var response = await _chatModel.GetResponseAsync(messages);
        
        // Cache successful responses
        await _cache.SetAsync(messages, null, response, TimeSpan.FromMinutes(30));
        
        // Record metrics
        _monitor.RecordMetric("ResponseLength", response.Content.Length);
        _monitor.IncrementCounter("RequestsProcessed");
        
        return response;
    }
}
```

### Resilience and Error Handling

```csharp
public class ResilientChatService
{
    public async Task<string> GetResponseWithRetryAsync(IEnumerable<ChatMessage> messages)
    {
        var retryPolicy = Policy
            .Handle<AiSdkRateLimitException>()
            .Or<HttpRequestException>()
            .WaitAndRetryAsync(
                retryCount: 3,
                sleepDurationProvider: attempt => TimeSpan.FromSeconds(Math.Pow(2, attempt)),
                onRetry: (outcome, timespan, retryCount, context) =>
                {
                    _logger.LogWarning("Retry {RetryCount} after {Delay}ms", retryCount, timespan.TotalMilliseconds);
                });

        return await retryPolicy.ExecuteAsync(async () =>
        {
            var response = await _chatModel.GetResponseAsync(messages);
            return response.Content;
        });
    }
}
```

## ğŸ—ï¸ Architecture

FluentAI.NET follows clean architecture principles with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Controllers   â”‚ â”‚    Services     â”‚ â”‚  Components  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FluentAI.NET Abstractions                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   IChatModel    â”‚ â”‚  IInputSanitizerâ”‚ â”‚ IPerformance â”‚   â”‚
â”‚  â”‚                 â”‚ â”‚                 â”‚ â”‚   Monitor    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Provider Layer                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   OpenAI    â”‚ â”‚  Anthropic  â”‚ â”‚   Google    â”‚ â”‚ Custom â”‚ â”‚
â”‚  â”‚  Provider   â”‚ â”‚   Provider  â”‚ â”‚   Provider  â”‚ â”‚Providerâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Components:**
- **Abstractions Layer**: Core interfaces and models
- **Provider Layer**: AI service implementations
- **Configuration Layer**: Strongly-typed configuration
- **Security Layer**: Input validation and risk assessment
- **Performance Layer**: Caching, monitoring, and optimization
- **Extensions Layer**: Dependency injection and fluent configuration

## ğŸ“– Documentation

### ğŸ“š **Core Documentation**
- **[API Reference](docs/API-Reference.md)** - Complete API documentation with examples
- **[Architecture Guide](docs/architecture.md)** - System design, components, and patterns
- **[Code Examples](docs/code-examples.md)** - Practical examples for common scenarios
- **[Security Guide](SECURITY.md)** - Security best practices and compliance
- **[Contributing Guide](CONTRIBUTING.md)** - Development guidelines and processes

### ğŸ“Š **Quality Assurance**
- **[Audit Executive Summary](docs/AUDIT-EXECUTIVE-SUMMARY.md)** - â­ Feature audit results and coverage analysis
- **[Feature Audit Report](docs/FEATURE-AUDIT-REPORT.md)** - Detailed feature-by-feature verification
- **[Coverage Remediation Plan](docs/COVERAGE-REMEDIATION-PLAN.md)** - Roadmap to 90%+ coverage
- **[Feature Checklist](docs/FEATURE-CHECKLIST.md)** - Complete feature tracking and status

### ğŸ› ï¸ **Integration Guides**
- **[Console Applications](docs/integration/console-applications.md)** - Complete setup with DI
- **[ASP.NET Core](docs/integration/aspnet-core.md)** - Web APIs with middleware
- **[Blazor](docs/integration/blazor.md)** - Interactive web UIs with real-time streaming
- **[Common Patterns](docs/integration/common-patterns.md)** - Best practices and reusable code
- **[Troubleshooting](docs/integration/troubleshooting.md)** - Common issues and solutions

### ğŸ”§ **Advanced Topics**
- **[Performance Optimization Guide](docs/PERFORMANCE-OPTIMIZATION-GUIDE.md)** - â­ Complete guide: caching, batch processing, token optimization, benchmarking
- **[Cost Optimization Guide](docs/COST-OPTIMIZATION-GUIDE.md)** - â­ Reduce costs by 40-92%: smart routing, caching strategies, ROI calculations
- **[Provider Best Practices](docs/PROVIDER-BEST-PRACTICES.md)** - â­ OpenAI, Anthropic, Google: configuration, patterns, failover strategies
- **[Roadmap Implementation](docs/ROADMAP-IMPLEMENTATION.md)** - â­ Complete feature guide: backpressure, batch ops, semantic cache, memory management
- **[Security Implementation](docs/code-examples.md#security-features)** - Input validation, content filtering, PII detection
- **[Error Handling](docs/code-examples.md#error-handling)** - Resilience patterns, retry logic
- **[RAG Implementation](docs/code-examples.md#rag-retrieval-augmented-generation)** - Document indexing, vector search, context-aware responses

## ğŸ› ï¸ Developer Tools

FluentAI.NET provides comprehensive developer tools for testing, debugging, and rapid prototyping:

### **CLI Tool** ğŸ–¥ï¸
Interactive command-line interface for model testing and benchmarking.

```bash
cd Tools/FluentAI.CLI
dotnet run -- chat                    # Interactive chat
dotnet run -- benchmark               # Performance testing
dotnet run -- stream                  # Streaming visualization
dotnet run -- diagnostics test        # Connectivity testing
```

**Features:**
- Interactive chat with conversation history
- Performance benchmarking across models
- Real-time streaming visualization
- Configuration management and validation
- Error diagnostics and troubleshooting

[ğŸ“– CLI Tool Documentation](Tools/FluentAI.CLI/README.md)

### **Visual Debugging Dashboard** ğŸ“Š
Real-time monitoring dashboard for AI operations.

```bash
cd Tools/FluentAI.Dashboard
dotnet run
# Navigate to https://localhost:5001
```

**Features:**
- Real-time token usage tracking
- Performance and cost metrics
- Cache hit/miss visualization
- Memory usage monitoring
- Auto-refresh dashboard (2s intervals)
- Test request interface

[ğŸ“– Dashboard Documentation](Tools/FluentAI.Dashboard/README.md)

### **Project Templates** ğŸš€
Ready-to-use templates for quick integration.

```bash
# Console Application
cd Templates/console
dotnet run

# ASP.NET Core Web API
cd Templates/webapi
dotnet run
# Navigate to https://localhost:5001/swagger
```

**Available Templates:**
- **Console App** - Basic chat with configuration management
- **Web API** - REST endpoints with Swagger documentation
- **Blazor App** - Coming soon
- **RAG-Enabled App** - Coming soon

[ğŸ“– Templates Documentation](Templates/README.md)

**Comprehensive Guide:** [Developer Tools Guide](docs/tools/developer-tools-guide.md)

## ğŸ§ª Examples & Demos

### ğŸ® **Interactive Console Demo**

Explore all SDK features with our comprehensive console application:

```bash
cd Examples/ConsoleApp
dotnet run
```

**Features Demonstrated:**
- ğŸ’¬ Basic chat completion with multiple providers
- ğŸŒŠ Real-time streaming responses
- ğŸ”„ Provider comparison and failover
- ğŸ”’ Security features and input sanitization
- âš¡ Performance monitoring and caching
- âš™ï¸ Configuration management
- ğŸš¨ Error handling and resilience patterns

### ğŸ“ **Code Examples**

#### Simple Chat
```csharp
var messages = new[] { new ChatMessage(ChatRole.User, "Hello!") };
var response = await chatModel.GetResponseAsync(messages);
Console.WriteLine(response.Content);
```

#### Streaming Chat
```csharp
await foreach (var token in chatModel.StreamResponseAsync(messages))
{
    Console.Write(token);
}
```

#### Multiple Providers
```csharp
// Configuration-based provider switching
var openAIResponse = await openAIModel.GetResponseAsync(messages);
var anthropicResponse = await anthropicModel.GetResponseAsync(messages);

// Compare responses or use as fallback
```

## ğŸ› ï¸ Integration Guides

### **Quick Integration Matrix**

| Project Type | Complexity | Setup Time | Guide |
|--------------|------------|------------|-------|
| Console App | â­ Simple | 5 minutes | [ğŸ“– Guide](docs/integration/console-applications.md) |
| ASP.NET Core | â­â­ Medium | 15 minutes | [ğŸ“– Guide](docs/integration/aspnet-core.md) |
| Blazor Server | â­â­ Medium | 20 minutes | [ğŸ“– Guide](docs/integration/blazor.md) |
| Blazor WASM | â­â­â­ Advanced | 30 minutes | [ğŸ“– Guide](docs/integration/blazor.md) |
| Class Library | â­ Simple | 10 minutes | [ğŸ“– Guide](docs/integration/class-libraries.md) |
| Azure Functions | â­â­ Medium | 15 minutes | [ğŸ“– Guide](docs/integration/azure-functions.md) |

### **Configuration Patterns**

All integration guides include:
- âœ… Step-by-step setup instructions
- âœ… Complete working code examples
- âœ… Configuration best practices
- âœ… Security considerations
- âœ… Performance optimization
- âœ… Testing strategies
- âœ… Troubleshooting tips

## ğŸ” Security

### **Built-in Security Features**

```csharp
// Input sanitization
var sanitizer = serviceProvider.GetRequiredService<IInputSanitizer>();
var safeContent = sanitizer.SanitizeContent(userInput);
var riskLevel = sanitizer.AssessRisk(userInput);

// Secure logging (automatic API key redaction)
_logger.LogInformation("Processing request from {UserId}", userId);
// API keys are automatically redacted from logs

// Content filtering
if (riskLevel.RiskLevel >= SecurityRiskLevel.High)
{
    throw new SecurityException("High-risk content detected");
}
```

### **Security Best Practices**

- ğŸ”‘ **API Key Management**: Environment variables, Azure Key Vault integration
- ğŸ›¡ï¸ **Input Validation**: Prompt injection detection and prevention
- ğŸ” **Content Filtering**: Configurable safety filters and risk assessment
- ğŸ“ **Secure Logging**: Automatic redaction of sensitive information
- ğŸš« **Rate Limiting**: Prevent abuse and DoS attacks
- ğŸ” **Compliance**: GDPR, CCPA, SOC 2 compliance support

## âš¡ Performance

### **Performance Features**

- **Response Caching**: Intelligent caching with configurable TTL
- **Streaming Support**: Real-time token streaming for better UX
- **Memory Management**: Efficient memory usage and cleanup
- **Connection Pooling**: Optimized HTTP client management
- **Metrics Collection**: Built-in performance monitoring

### **Benchmarks**

| Feature | Performance | Memory Usage | Throughput |
|---------|-------------|--------------|------------|
| Basic Chat | ~500ms | 5MB | 100 req/min |
| Streaming | ~50ms TTFB | 3MB | 200 req/min |
| Cached Response | ~10ms | 2MB | 1000 req/min |
| Batch Processing | ~2s/10 req | 15MB | 300 req/min |

*Benchmarks vary based on provider, model, and network conditions.*

### **Performance Monitoring**

```csharp
// Built-in performance monitoring
var monitor = serviceProvider.GetRequiredService<IPerformanceMonitor>();

using var operation = monitor.StartOperation("ChatCompletion");
var response = await chatModel.GetResponseAsync(messages);

// Automatic metrics collection
// - Request duration
// - Token usage
// - Success/failure rates
// - Memory usage
```

## ğŸ§ª Testing

### **Test Suite Overview**

- **Comprehensive Test Suite** with 87% average coverage ([audit report](docs/AUDIT-EXECUTIVE-SUMMARY.md))
- **Unit Tests**: Fast, isolated tests for all components
- **Integration Tests**: Real provider testing with API keys
- **Performance Tests**: Benchmarking and load testing
- **Security Tests**: Vulnerability and penetration testing

**Coverage by Feature:**
- Core Chat: 90% âœ…
- Security: 90% âœ…
- RAG: 85-88% âš ï¸
- Performance: 85% âš ï¸
- MCP: 85% âš ï¸
- Analysis: 82% âš ï¸

### **Testing Your Integration**

```csharp
// Unit testing with mocks
[Test]
public async Task GetResponse_ShouldReturnExpectedContent()
{
    var mockChatModel = new Mock<IChatModel>();
    mockChatModel.Setup(x => x.GetResponseAsync(It.IsAny<IEnumerable<ChatMessage>>(), null, default))
        .ReturnsAsync(new ChatResponse { Content = "Test response" });

    var service = new ChatService(mockChatModel.Object);
    var result = await service.GetResponseAsync("Test message");

    Assert.AreEqual("Test response", result);
}

// Integration testing
[Test, Category("Integration")]
public async Task RealProvider_ShouldWork()
{
    var services = new ServiceCollection();
    services.AddAiSdk(Configuration).AddOpenAiChatModel(Configuration);
    
    using var provider = services.BuildServiceProvider();
    var chatModel = provider.GetRequiredService<IChatModel>();
    
    var response = await chatModel.GetResponseAsync(testMessages);
    Assert.IsNotEmpty(response.Content);
}
```

### **Running Tests**

```bash
# Run all tests
dotnet test

# Run only unit tests
dotnet test --filter Category!=Integration

# Run with coverage
dotnet test --collect:"XPlat Code Coverage"

# Run performance tests
dotnet test --filter Category=Performance
```

## ğŸ¤ Contributing

We welcome contributions! See our [Contributing Guide](CONTRIBUTING.md) for:

- ğŸ› **Bug Reports** - Help us identify and fix issues
- âœ¨ **Feature Requests** - Suggest new capabilities
- ğŸ“– **Documentation** - Improve guides and examples
- ğŸ§ª **Testing** - Add test coverage and scenarios
- ğŸ”§ **Code Contributions** - Submit pull requests

### **Quick Start for Contributors**

```bash
# Fork and clone
git clone https://github.com/YOUR_USERNAME/fluentai-dotnet.git
cd fluentai-dotnet

# Build and test
dotnet restore
dotnet build
dotnet test

# Make your changes and submit a PR
```

**Development Requirements:**
- .NET 8.0 SDK
- API keys for testing (optional)
- IDE with C# support

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

**Key Points:**
- âœ… Commercial use allowed
- âœ… Modification and distribution allowed
- âœ… Private use allowed
- âŒ No warranty provided
- âŒ No liability assumed
